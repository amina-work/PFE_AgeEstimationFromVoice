{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "#importing dataset\n",
    "file_paths = [\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-valid-train.csv\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-other-train.csv\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-invalid.csv\"\n",
    "]\n",
    "\n",
    "dfs_train = []\n",
    "for i in file_paths:\n",
    "    df_train = pd.read_csv(i)\n",
    "    dfs_train.append(df_train)\n",
    "\n",
    "df_train = pd.concat(dfs_train, ignore_index=True)\n",
    "\n",
    "file_paths2 = [\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-valid-dev.csv\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-other-dev.csv\",\n",
    "]\n",
    "dfs_val = []\n",
    "for i in file_paths2:\n",
    "    df_val = pd.read_csv(i)\n",
    "    dfs_val.append(df_val)\n",
    "df_val = pd.concat(dfs_val, ignore_index=True)\n",
    "\n",
    "file_paths3 = [\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-valid-test.csv\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-other-test.csv\",\n",
    "]\n",
    "dfs_test = []\n",
    "for i in file_paths3:\n",
    "    df_test = pd.read_csv(i)\n",
    "    dfs_test.append(df_test)\n",
    "\n",
    "df_test = pd.concat(dfs_test, ignore_index=True)\n",
    "\n",
    "#data cleaning\n",
    "df_train = df_train.dropna(subset=['age'])\n",
    "df_train = df_train[[\"filename\",\"age\",\"gender\",\"accent\"]]\n",
    "df_train[\"gender\"].fillna(\"other\", inplace=True)\n",
    "df_train = df_train.dropna(subset=['accent'])\n",
    "#same for validation set\n",
    "df_val = df_val.dropna(subset=['age'])\n",
    "df_val = df_val[[\"filename\",\"age\",\"gender\",\"accent\"]]\n",
    "df_val[\"gender\"].fillna(\"other\", inplace=True)\n",
    "df_val = df_val.dropna(subset=['accent'])\n",
    "#same for testing set\n",
    "df_test = df_test.dropna(subset=['age'])\n",
    "df_test = df_test[[\"filename\",\"age\",\"gender\",\"accent\"]]\n",
    "# Convert 'age' column to numerical\n",
    "cleanup_nums = {\"age\": {\"teens\":1.0,\"twenties\":2.0,\"thirties\":3.0,\"fourties\":4.0,\"fifties\":5.0,\"sixties\":6.0,\"seventies\":7.0,\"eighties\":8.0}}\n",
    "df_test = df_test.replace(cleanup_nums)\n",
    "df_train = df_train.replace(cleanup_nums)\n",
    "#Convert categorical variables to numerical using one-hot encoding\n",
    "df_train = pd.get_dummies(df_train, columns=['gender', 'accent'])\n",
    "df_test = pd.get_dummies(df_test, columns=['gender', 'accent'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([#define  a linear stack of layers for the mode\n",
    "    Embedding(input_dim=len(df_train.columns)-1, output_dim=64, input_length=1),#map categorical variables to dense vectors.\n",
    "    LSTM(units=64, activation='tanh', dropout=0.2, recurrent_dropout=0.2),#work for sequential data\n",
    "    Dense(32, activation='relu'),#fully connected layer with 32 neurons and ReLU activation function\n",
    "    Dropout(0.5),#prevent overfitting by randomaly setting fraction of input units to 0 at each update\n",
    "    Dense(8, activation='softmax')  # Softmax activation for multi-class classification to output probabilities for each class\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Adam is an optimization algorithm that is an extension to stochastic gradient descent\n",
    "#Sparse categorical cross-entropy is commonly used in multi-class classification problems where the labels are integers\n",
    "\n",
    "# Define training and validation data\n",
    "X_train = df_train.drop(columns=['filename', 'age']).values\n",
    "y_train = df_train['age'].values - 1  # Convert labels to start from 0\n",
    "X_val = df_val.drop(columns=['filename', 'age']).values\n",
    "y_val = df_val['age'].values - 1  # Convert labels to start from 0\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "# An epoch is one complete pass through the entire training dataset.\n",
    "\n",
    "# Evaluate the model on test data\n",
    "X_test = df_test.drop(columns=['filename', 'age']).values\n",
    "y_test = df_test['age'].values - 1  # Convert labels to start from 0\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing steps\n",
    "filename_preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  \n",
    "    ('encoder', OneHotEncoder())  \n",
    "])\n",
    "\n",
    "text_preprocessor = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),  \n",
    "])\n",
    "\n",
    "# Combine preprocessing steps for all features\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('filename', filename_preprocessor, ['filename']),\n",
    "    ('text', text_preprocessor, 'text'),  \n",
    "    ('other', 'passthrough', df.select_dtypes(exclude=\"object\").columns)  \n",
    "])\n",
    "\n",
    "# Split data into X (predictors) and y (target)\n",
    "X = df.drop(columns=['age'])\n",
    "y = df['age']\n",
    "\n",
    "# Split text data\n",
    "text_data = X['text']\n",
    "\n",
    "# Tokenize text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "X_text = tokenizer.texts_to_sequences(text_data)\n",
    "X_text = pad_sequences(X_text, maxlen=100)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, X_text_train, X_text_test, y_train, y_test = train_test_split(X, X_text, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define input layers for numeric and text data\n",
    "numeric_input = Input(shape=(X_train.shape[1],))\n",
    "text_input = Input(shape=(X_text_train.shape[1],))  # Use the shape of preprocessed text data\n",
    "\n",
    "# Define embedding layer for categorical data (filename)\n",
    "filename_embedding = Embedding(input_dim=len(df['filename'].unique()), output_dim=64, input_length=1)(numeric_input)\n",
    "\n",
    "# LSTM layer for text data\n",
    "lstm_layer = LSTM(units=64, activation='tanh', dropout=0.2, recurrent_dropout=0.2)(text_input)\n",
    "\n",
    "# Concatenate numerical and text embeddings\n",
    "concatenated = concatenate([filename_embedding, lstm_layer])\n",
    "\n",
    "# Additional layers\n",
    "dense_layer = Dense(32, activation='relu')(concatenated)\n",
    "dropout_layer = Dropout(0.5)(dense_layer)\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(8, activation='softmax')(dropout_layer)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[numeric_input, text_input], outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit([X_train, X_text_train], y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate([X_test, X_text_test], y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing the audio samples\n",
    "# Function to play audio file\n",
    "def play_audio(audio_path):\n",
    "    display(Audio(filename=audio_path))\n",
    "\n",
    "# Specify the folder paths containing MP3 files\n",
    "folder_paths = [\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-invalid/cv-invalid\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-other-dev/cv-other-dev\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-other-test/cv-other-test\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-other-train/cv-other-train\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-valid-dev/cv-valid-dev\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-valid-test/cv-valid-test\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-valid-train/cv-valid-train\",\n",
    "]\n",
    "# Iterate through each folder path\n",
    "for folder_path in folder_paths:\n",
    "    # Get the list of all files in the folder and sort them\n",
    "    all_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.mp3')])\n",
    "    # Get the total file count\n",
    "    total_files = len(all_files)\n",
    "    print(f'Total number of MP3 files in the folder: {total_files}')\n",
    "    \n",
    "    # Check if there are MP3 files in the folder\n",
    "    if len(all_files) == 0:\n",
    "        print(f\"No MP3 files found in {folder_path}\")\n",
    "    else:\n",
    "        # Select the first MP3 file in the folder\n",
    "        file_path = os.path.join(folder_path, all_files[0])\n",
    "        # Play the audio file\n",
    "        print(f'Playing file: {all_files[0]}')\n",
    "        play_audio(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features\n",
    "#Spectral Centroid + Spectral Bandwidth + Spectral Rolloff + MFCCs\n",
    "#this function is used to extract audio frequency features\n",
    "\n",
    "# Specify the folder paths containing MP3 files\n",
    "folder_paths = [\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-invalid/cv-invalid\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-other-dev/cv-other-dev\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-other-test/cv-other-test\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-other-train/cv-other-train\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-valid-dev/cv-valid-dev\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-valid-test/cv-valid-test\",\n",
    "    \"D:/AMINA/PFE24/datasets/commonvoice/cv-valid-train/cv-valid-train\",\n",
    "]\n",
    "def feature_extraction(filename, folder_path, sampling_rate=48000):\n",
    "    path = os.path.join(folder_path, filename)\n",
    "    features = []\n",
    "    audio, _ = librosa.load(path, sr=sampling_rate)\n",
    "    \n",
    "    # Extract age label from DataFrame based on filename\n",
    "    #age = df[df['filename'] == filename].age.values[0]\n",
    "    # Extract age label from DataFrame based on full file path\n",
    "    # Construct the full file path to match with DataFrame\n",
    "    full_file_path = os.path.join(os.path.basename(folder_path), filename)\n",
    "    \n",
    "    # Filter DataFrame based on full file path\n",
    "    filtered_df = df[df['filename'] == full_file_path]\n",
    "    \n",
    "    # Check if DataFrame is empty (no entry found for the filename)\n",
    "    if filtered_df.empty:\n",
    "        print(f\"No entry found in DataFrame for file: {full_file_path}. Skipping...\")\n",
    "        return None  # Skip this filename and move on to the next one\n",
    "    \n",
    "    age = filtered_df.age.values[0]\n",
    "    \n",
    "    # Feature extraction\n",
    "    features.append(age)\n",
    "    features.append(np.mean(librosa.feature.spectral_centroid(y=audio, sr=sampling_rate)))\n",
    "    features.append(np.mean(librosa.feature.spectral_bandwidth(y=audio, sr=sampling_rate)))\n",
    "    features.append(np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sampling_rate)))\n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sampling_rate)\n",
    "    for el in mfcc:\n",
    "        features.append(np.mean(el))\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract features for all files in all folder paths\n",
    "all_features = []\n",
    "for folder_path in folder_paths:\n",
    "    files = os.listdir(folder_path)\n",
    "    for file in files:\n",
    "        file_features = feature_extraction(file, folder_path)\n",
    "        all_features.append(file_features)\n",
    "\n",
    "print(\"features: \", all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MFCC per age\n",
    "mfcc_features = []\n",
    "age_labels = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    audio_path = row['filename']  # Replace 'audio_path' with the column name containing the file paths\n",
    "    age_label = row['age']     # Replace 'age_label' with the column name containing the age labels\n",
    "    \n",
    "    audio_array, sampling_rate = librosa.load(audio_path, sr=sample_rate)\n",
    "    mfcc = librosa.feature.mfcc(y=audio_array, sr=sample_rate, n_mfcc=20)  # You can change n_mfcc to 10 if needed\n",
    "    \n",
    "    mfcc_features.append(mfcc)\n",
    "    age_labels.append(age_label)\n",
    "\n",
    "# Visualize MFCC features for different age groups\n",
    "sns.boxplot(x=age_labels, y=mfcc_features)\n",
    "plt.xlabel('Age Label', fontsize=14)\n",
    "plt.ylabel('MFCC', fontsize=14)\n",
    "plt.title('MFCC Variation with Age', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx in range(num_batches):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min((batch_idx + 1) * batch_size, total_images)\n",
    "    \n",
    "    batch_paths = image_paths[start_idx:end_idx]\n",
    "    batch_images = []\n",
    "    \n",
    "    for img_path in batch_paths:\n",
    "        img = image.load_img(img_path)\n",
    "        img = image.img_to_array(img)\n",
    "        img = img / 255.0\n",
    "        batch_images.append(img)\n",
    "    \n",
    "    images.extend(batch_images)\n",
    "    print(f\"Processed batch {batch_idx + 1}/{num_batches}\")\n",
    "\n",
    "images = np.array(images)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
